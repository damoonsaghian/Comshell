= computers
cpu, memory, peripherals,
  this seems to be the only practical architecture for the hardware of computers;
cpu runs a sequence of simple computations called instructions (packages of 0 and 1),
  one by one;

compilers are special programs that obtain computer instructions
  from a program written in a language which is structured and human readable;
  this way the written program will be portable to different computer architectures;
Rust is a programming language which provides zero cost abstractions,
  and memory safety without garbage collection;
  thus there is absolutely no reason to write new software in C/C++;

programs usually do not run directly on computer hardware;
instead they run on a more sophisticated software machine (a virtual machine) called kernel;
in theory we can live without a kernel (an idea sometimes called a library operating system);
but in that case, we have to rewrite all the required libraries, on bare metal;
more importantly, this means that we can't have more than one program;
  developing new programs on such a system will be difficult, if not impossible;

Linux is a highly developed, constantly evolving, open_source kernel;
in Linux (and other Unix based operating systems) most things appear in the file system;
  i think the reason is to make it possible to do a lot of things using shell scripts
    instead of a proper programming language;
  while i can understand the convenience it provides, i don't think it's good design;
"https://dominuscarnufex.github.io/cours/rs-kernel/en.html"

= Rust
Rust makes bad programming hard, and good programming fun;
Rust does not hide (inherent) complexity, in fact it bolds it, so we can see it, and avoid it;
by inherent complexity i mean a complexity which can not be abstracted away completely;
  ie if we attempt to hide it, it will re_emerge somewhere else;
furthermore hiding inherent complexity usually leads to choosing wrong approaches;

Rust doen not hide the complexities of managing references behind a garbage collector;
"https://manishearth.github.io/blog/2015/05/17/the-problem-with-shared-mutability/"
"http://blog.skylight.io/rust-means-never-having-to-close-a-socket/"

if a data has a fixed structure we usually put it on stack;
so we don't share it across the program, we copy it;
if the data is big and we want to share it, we put it inside a cell on the heap,
  and share references to it across the program, using &;
since the structure of data is fixed we can mutate it from anywhere (in the same tread);

but in general where the structure of data is not fixed,
  we need to check if the RWlock pattern is fulfilled,
  either statically (when sharing refs using &mut),
  or dynamically at runtime, by putting it inside a RefCell
    (or its multi_threaded counterparts: Mutex or RwLock);
note that if write our program in a way which breaks runtime RWlock, it will panic;
this is true even for garbage collected languages,
  and can be seen in rare occasions like iteration invalidation;
  you see? inherent complexities can't be hidden completely;

a type is "Copy" if all the data it owns is part of its stack representation;
  in other words if a copy of its stack representation doesn't violate memory safety;
"&T" and raw pointers are copy, "&mut T" is move (not copy);

in Rust any resource have exactly one owner which takes care of its resource deallocation;
owners can share their data by lending them to references;
references must have a lifetime less than the owner;
furthermore lifetime of a mutable reference must not overlap with other references;

owner can:
, access and mutate resource;
, lend the resource to a reference;
, hand over ownership (move), or deallocate resource;
but during a lend, owner can't:
, mutate the resource;
, mutably lend resouce to another reference;
, hand over ownership (move), or deallocate resource;
and during a mutable lend, owner can't even access the resource;

references (shared references) can:
, access borrowed resource;
, immutably lend resource to other references;
mutable reference (exclusive reference) can:
, access and mutate resource;
, mutably lend resouce to another reference;
  they can immutably lend resource, but then they can mutate it;
  just like when an owner immutably lends its resource;

during shared borrow (immutable borrow) no one owns the data;
  so even the original owner can't change the it;
during mutable borrow the (unique) borrower owns it;
so "&mut" is actually a temporary transfer of ownership;

RC: shared owning (a runtime solution);
ARC: multi_threaded;

sync sharing (& and &mut) can be checked statically;
async sharing needs runtime checking, so it's better to move/copy in async situations;

scenarios that involve returning refs often require explicit lifetimes;
  so don't return refs, instead use mutable refs in inputs;
structs and enums containing refs must have explicit lifetimes;
  so don't use them;

s: String -> &s: &String -> &s[..]: &str
v: Vec<T> -> &v: &Vec<T> -> &v[..]: &[T]
&str and &[T] are slices; str and [T] are unsized types;
slicing is like borrowing from an unsized type;
since the the slice contains the size, the lending type itself doesn't need to have a definite size;

x = a[i] -> this is possible if the elements of "a" are copy
  (cause moving out of collections is not possible);
x = &a[i] -> this is for the case when the elements are not copy;
x = a[i..j] -> this is always invalid;
x = &a[i..j] -> slicing;

auto ref/deref for self in method calls:
  insert as many * or & as necessary to get it right;
cause in method calls name and context of a method call is almost always sufficient
  to infer the move/borrow semantics;

deref coercion:
, &T -> &U when T: Deref<Target=U>
, &mut T -> &U when T: Deref<Target=U>
, &mut T -> &mut U when T: DerefMut<Target=U>
examples:
  &&i32 -> &i32 because &i32: Deref<Target=i32>
  &String -> &str because String: Deref<Target=str>
  &Vec<T> -> &[T] because Vec<T>: Deref<Target=[T]>
"https://github.com/rust-lang/rfcs/blob/master/text/0241-deref-conversions.md"

= type system
types show us what we can do with the data (which operations are valid);

the class hierarchy design like in Java is problematic;
  "http://ptgmedia.pearsoncmg.com/images/020163371x/items/item33.html"
also the problem of covariance for generic types, has its root in this problem;
  "https://en.wikipedia.org/wiki/Wildcard_(Java)"
i think this is also the motivation for dynamic typing (another bad design);
the right way as done in Rust, Go and Julia:
, concrete types (like final classes in Java) can be instantiated, but cannot have subtypes;
, abstract types (like abstract classes in Java) cannot be instantiated, but can have subtypes;

note that "x.m()" is method call syntax, which completely differs from "(x.m)()";

in "use" statements:
, crate_name::...
, self::local_item::...
even outside "use" statements, we can build absolute paths using crate names at the begining;
  but since it can conflict with a local name, it's better to avoid it, and instead,
  either insert a "::" at the begining, before the crate's name,
  or bring the crate's name into scope using a "use" statement;

arrays like tuples have fixed size and thus stored on stack;
  but since they are homogeneous (all elements are of the same type), they can be indexed at runtime;
vectors and hash tables are homogeneous, varying sized collection;

Rust does not have named arguments and named tuples; and it's a good thing;
when you need functions with lots of arguments, or tuples with lots of elements,
  it could indicate that you need to restructure your code and use structs to define new types;

in Rust each closure has its own unique, un_writable type;
  they do implement the "Fn" family of traits, however;
note that if we put a generic type parameter in the return type of a fuction,
  we have to provide the concrete type when we call the function;
  thus we can't use generic type parameters to return a closure, we have to use "impl";
cause closures are like anonymous structs made of variables captured from environment;
"fn(T1) -> T2" is not an unsized type like "str", it's a function pointer;

= message passing
imperative programming is done by procedurally changing stored values,
  it resembles the way CPU runs the instructions stored in memory;
imperative programming leads to unmaintainable code in large programs
  (even if we hide the mentioned complexities behind a garbage collector),
  and it makes writing parallel programs a cumbersome task;

in message passing programming, we have a number of async processes;
when a process recieves a message,
  it may change its internal state, and send messages to other processes;

, static data (functions, structs, constants): no problem, copy or share by reference;
, dynamic data:
  , small data: copy;
  , big data: move;
message passing programming allows us to program without the need to share big data;
this means that we won't need:
  , complex reference sharing, which needs lifetime indication;
  , shared mutability (RefCell) or shared ownership (RC), which needs runtime solutions;

a process can have a set of parameters which can be adjusted based on the recieved messages;
  so processes can have learning capabilities;

we need asynchronous sends and unbounded channels;

async processes:
"https://docs.rs/threadpool"
"https://docs.rs/jobpool"
"https://crates.io/crates/threads_pool" (depends on crossbeam)
"https://docs.rs/rayon-core/*/rayon_core/struct.ThreadPool.html" (depends on crossbeam)

use "std::sync::mpsc" channels for message passing;
